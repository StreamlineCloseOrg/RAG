{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import csv\n",
    "import pandas as pd\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from pinecone.exceptions import PineconeApiException \n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get env variables\n",
    "# Get the current working directory\n",
    "current_directory = os.getcwd()\n",
    "# Construct the path to the .env file in the parent directory if any\n",
    "env_path = os.path.join(current_directory, '..', '.env')\n",
    "# Load the environment variables from the .env file or just hardcode your keys here\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "PINECONE_API_KEY = os.getenv('PINECONE_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_dict(csv_file_path):\n",
    "    \"\"\"\n",
    "    Convert a CSV file into a dictionary where the key is the first column.\n",
    "\n",
    "    Args:\n",
    "        csv_file_path (str): The path to the CSV file.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary representation of the CSV data with the first column as keys.\n",
    "    \"\"\"\n",
    "    result_dict = {}\n",
    "    \n",
    "    # Open and read the CSV file\n",
    "    with open(csv_file_path, mode='r', newline='') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        \n",
    "        # Convert each row into a dictionary item\n",
    "        for row in reader:\n",
    "            key = row[reader.fieldnames[0]]  # Use the first column as the key\n",
    "            result_dict[key] = {field: row[field] for field in reader.fieldnames[1:]}  # Use remaining columns as values\n",
    "    \n",
    "    return result_dict\n",
    "\n",
    "def dict_to_csv(data_dict, csv_file_path):\n",
    "    \"\"\"\n",
    "    Convert a dictionary to a DataFrame and save it to a CSV file.\n",
    "\n",
    "    Args:\n",
    "        data_dict (dict): The dictionary to be converted to a CSV file.\n",
    "        csv_file_path (str): The path where the CSV file will be saved.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Convert the dictionary to a DataFrame\n",
    "    df = pd.DataFrame.from_dict(data_dict, orient='index')\n",
    "    \n",
    "    # Save the DataFrame to a CSV file\n",
    "    df.to_csv(csv_file_path)\n",
    "    \n",
    "    print(f\"Data has been written to {csv_file_path}\")\n",
    "\n",
    "def select_pinecone_index(pc, index_name):\n",
    "\n",
    "  # List current indexes to ensure the check is accurate\n",
    "  current_indexes = pc.list_indexes()\n",
    "\n",
    "  if index_name not in current_indexes:\n",
    "      try:\n",
    "          pc.create_index(\n",
    "              name=index_name,\n",
    "              dimension=1536, # 1536 dim of text-embedding-ada-002\n",
    "              metric=\"cosine\", # Replace with your model metric\n",
    "              spec=ServerlessSpec(\n",
    "                  cloud=\"aws\",\n",
    "                  region=\"us-east-1\"\n",
    "              ) \n",
    "          )\n",
    "      except PineconeApiException as e:\n",
    "          if \"ALREADY_EXISTS\" in str(e):\n",
    "              print(f\"Index '{index_name}' already exists.\")\n",
    "          else:\n",
    "              raise\n",
    "  else:\n",
    "      print(f\"Index '{index_name}' already exists.\")\n",
    "\n",
    "  return pc.Index(index_name)\n",
    "\n",
    "def upsert_embeddings_to_pinecone(index, data_dict, batch_size=100):\n",
    "    \n",
    "    \"\"\"\n",
    "    Generate embeddings for each key in a dictionary and upsert them to a Pinecone index.\n",
    "\n",
    "    Args:\n",
    "        index (object): The Pinecone index to upsert vectors to.\n",
    "        data_dict (dict): The input dictionary containing data. \n",
    "                          Each key should be the text to embed, \n",
    "                          and the value should contain an 'id' field.\n",
    "        embed_function (function): The embedding function to use for generating embeddings.\n",
    "        batch_size (int): The number of vectors to upsert in each batch. Default is 100.\n",
    "    \"\"\"\n",
    "    # embeddings setup using OpenAI\n",
    "    model_name = 'text-embedding-ada-002'\n",
    "    embedder = OpenAIEmbeddings(\n",
    "        model=model_name,\n",
    "        openai_api_key=OPENAI_API_KEY\n",
    "    )\n",
    "    \n",
    "    # Create lists to store embeddings, metadata, and IDs\n",
    "    embeddings_list = []\n",
    "    metadata_list = []\n",
    "    ids = []\n",
    "\n",
    "    # Generate embeddings for each key in the data dictionary\n",
    "    for key in data_dict.keys():\n",
    "        vector = embedder.embed_query(key)\n",
    "        embeddings_list.append(vector)\n",
    "        metadata_list.append({'name': key})  # Store the name as metadata\n",
    "        ids.append(data_dict[key]['id'])\n",
    "\n",
    "    # Batch and upsert embeddings with metadata\n",
    "    for i in range(0, len(embeddings_list), batch_size):\n",
    "        batch_ids = ids[i:i + batch_size]\n",
    "        batch_vectors = embeddings_list[i:i + batch_size]\n",
    "        batch_metadata = metadata_list[i:i + batch_size]\n",
    "        \n",
    "        # Combine ids, vectors, and metadata into a single iterable\n",
    "        vectors_with_metadata = [\n",
    "            (batch_ids[j], batch_vectors[j], batch_metadata[j])\n",
    "            for j in range(len(batch_ids))\n",
    "        ]\n",
    "        \n",
    "        # Upsert vectors with metadata to the Pinecone index\n",
    "        index.upsert(vectors=vectors_with_metadata)\n",
    "\n",
    "def find_closest_matches(source_index_name, target_index_name, data_dict, pinecone_client, top_k=1):\n",
    "    \"\"\"\n",
    "    Query the Pinecone source index for each embedding and find the closest match in the target index.\n",
    "\n",
    "    Args:\n",
    "        source_index_name (str): The name of the Pinecone index containing the source embeddings.\n",
    "        target_index_name (str): The name of the Pinecone index to search for matching vectors.\n",
    "        data_dict (dict): A dictionary containing data with an 'id' field for each item.\n",
    "        pinecone_client (object): The initialized Pinecone client object.\n",
    "        top_k (int): The number of top matches to retrieve. Default is 1.\n",
    "\n",
    "    Returns:\n",
    "        dict: The updated data dictionary with matched vendor names and scores.\n",
    "    \"\"\"\n",
    "    # Initialize indexes once outside the loop\n",
    "    source_index = pinecone_client.Index(source_index_name)\n",
    "    target_index = pinecone_client.Index(target_index_name)\n",
    "\n",
    "    # Query the Pinecone index for each embedding and print the results\n",
    "    for key, values in data_dict.items():\n",
    "        # Get the item ID and fetch the corresponding vector from source index\n",
    "        item_id = values.get('id')\n",
    "        vector_data = source_index.fetch([item_id])['vectors'][item_id]\n",
    "\n",
    "        # Get the vector values\n",
    "        vector = vector_data['values']\n",
    "        \n",
    "        # Query the target index for the closest match\n",
    "        matching_result = target_index.query(vector=vector, top_k=top_k, include_metadata=True)\n",
    "        \n",
    "        # Get the top match\n",
    "        match = matching_result['matches'][0]\n",
    "        \n",
    "        # Extract metadata and score\n",
    "        name = match['metadata']['name']\n",
    "        score = match['score']\n",
    "        \n",
    "        # Update data_dict with the matching name and score\n",
    "        data_dict[key]['matched_vendor'] = name\n",
    "        data_dict[key]['score'] = score\n",
    "\n",
    "        print(f\"Closest match: {name} with a score of {score}\")\n",
    "    \n",
    "    return data_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load csv files into dictionaries\n",
    "csv_file_path = 'vendor_list_1.csv'\n",
    "vendors_dict_source = csv_to_dict(csv_file_path)\n",
    "csv_file_path = 'vendor_list_2.csv'\n",
    "vendors_dict_target = csv_to_dict(csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Pinecone client\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed and upsert the source and target dictionaries to Pinecone\n",
    "index_name_source = \"vendors-source\"\n",
    "index = select_pinecone_index(pc, index_name_source)\n",
    "upsert_embeddings_to_pinecone(index, vendors_dict_source, batch_size=100)\n",
    "index_name_target = \"vendors-target\"\n",
    "index = select_pinecone_index(pc, index_name_target)\n",
    "upsert_embeddings_to_pinecone(index, vendors_dict_target, batch_size=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the closest matches between the source and target vector databases\n",
    "matches_dict = find_closest_matches(index_name_source, index_name_target, vendors_dict_source, pc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the matched vendors to a CSV file\n",
    "dict_to_csv(matches_dict, 'matched_companies.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-testing-P8xkvbMm-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
